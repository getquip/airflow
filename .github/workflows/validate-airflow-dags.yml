name: Validate Airflow DAGs

# Trigger this workflow when a PR is opened or updated (commits pushed).
on:
  pull_request:
    types:
      - opened        # Trigger when a new PR is opened
      - synchronize   # Trigger when new commits are added to an open PR
      - reopened      # Trigger when a PR is reopened

env:
  AIRFLOW_VERSION: "2.10.2"  # Match the Airflow version in Composer 
  GH_TOKEN: ${{ github.token }}  # GitHub token to access the PR files
  
jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout the code to access the files in the PR
    - name: Checkout code
      uses: actions/checkout@v3

    # 2. Set up Python environment to run validation
    - name: Set up Python environment
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'  # Set up Python 3.9 (or your preferred version)

    # 3. Ensure the latest version of pip is installed
    - name: Upgrade pip
      run: |
        python -m pip install --upgrade pip

    # 4. Install the correct version of Apache Airflow
    - name: Install Airflow
      run: |
        CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-3.9.txt"
        pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"

    # 5. Find new or modified scripts in the `dag/` directory
    - name: Find new or modified DAGs
      id: find_dags
      run: |
        # Get the list of changed files in the PR using GitHub API
        changed_files=$(gh pr view ${{ github.event.pull_request.number }} --json files --jq '.files[].path')
        
        # Filter for scripts in the `dag/` folder that are not in `.airflowignore`
        if [ -f .airflowignore ]; then
          new_dag_files=$(echo "$changed_files" | grep "^dag/.*\.py$" | grep -v -F -f .airflowignore || true)
        else
          new_dag_files=$(echo "$changed_files" | grep "^dag/.*\.py$" || true)
        fi

        # Check if there are no new/modified DAG files
        if [ -z "$new_dag_files" ]; then
          echo "No new or modified DAG files. Exiting workflow."
          exit 0  # Exit the workflow if no new DAG files are found
        fi

        echo "New or modified DAG files:"
        echo "$new_dag_files"
        
        # Save the list of new/modified DAG files as an environment variable
        echo "new_dags=$new_dag_files" >> $GITHUB_ENV

    # 6. Validate if any new DAG scripts are valid
    - name: Validate new DAGs
      if: env.new_dags != ''  # Only run this step if there are new/modified DAG files
      run: |
        # Loop through each DAG file and validate
        IFS=' ' read -r -a dag_files <<< "$new_dags"
        for dag_file in "${dag_files[@]}"; do
          echo "Validating DAG: $dag_file"
          
          # Validate if the DAG file can be imported
          python -c "from airflow.models import DagBag; dag_bag = DagBag(dag_folder='dag/'); assert not dag_bag.import_errors, dag_bag.import_errors" || exit 1
        done
